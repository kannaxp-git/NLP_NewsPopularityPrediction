{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import codecs\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the contents containing repeating / unnecessary info - these classes are excluded\n",
    "exclude_class_list = [ \"top-stories-promo-story__summary\"]\n",
    "\n",
    "exclude_starts_with = [\"Additional reporting by\"]\n",
    "regex_keyword = \"\"\"<meta content=\"(?P<keyword1>[^><\\/\\\"]*)\"\\s[a-zA-Z=\"\\-]*\\sname=\"keywords\"\\s+\\/+>\"\"\"\n",
    "\n",
    "# Header info\n",
    "header_info = pd.DataFrame(columns=[\"Id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700, 1800, Issue in status code : 1826 : http://mashable.com/2014/09/29/sexting-photo-apps/ : 404\n",
      "1900, 2000, 2100, 2200, 2300, 2400, 2500, 2600, 2700, 2800, 2900, 3000, 3100, 3200, 3300, 3400, 3500, 3600, 3700, 3800, 3900, 4000, 4100, 4200, 4300, 4400, 4500, 4600, 4700, 4800, 4900, 5000, 5100, 5200, 5300, 5400, 5500, 5600, 5700, 5800, 5900, Issue in status code : 5935 : http://mashable.com/2014/11/26/storytelling-podcasts/ : 404\n",
      "6000, Issue in status code : 6043 : http://mashable.com/2014/11/29/egypt-court-drops-murder-charges-against-mubarak/ : 504\n",
      "6100, 6200, 6300, 6400, 6500, 6600, 6700, 6800, 6900, 7000, 7100, Issue in status code : 7144 : http://mashable.com/2014/12/16/books-holiday-gifts/ : 500\n",
      "Issue in status code : 7184 : http://mashable.com/2014/12/16/los-angeles-cosby-no-charges/ : 404\n",
      "7200, 7300, 7400, 7500, Issue in status code : 7513 : http://mashable.com/2014/12/22/best-content-delivery-networks/ : 404\n",
      "7600, 7700, \n"
     ]
    }
   ],
   "source": [
    "# Method to crawl\n",
    "df = pd.read_excel('../data/input/OnlineNewsPopularity.xlsx')\n",
    "df = df[[\"Id\", \"url\"]]\n",
    "\n",
    "df_out = pd.read_excel( \"../data/output/SS_Extracted_content.xlsx\")\n",
    "\n",
    "# for first time creation\n",
    "#df_out = pd.DataFrame(columns=[\"Id\", \"url\", \"title\", \"html\", \"txt\"])\n",
    "out_index = 0\n",
    "\n",
    "for index, rows in df.iterrows():\n",
    "    doc_id = df.at[ index, \"Id\"]\n",
    "    url = df.at[ index, \"url\"]\n",
    "    \n",
    "    if doc_id % 100 == 0:\n",
    "        print( str(doc_id) + \", \", end='')\n",
    "        df_out.to_excel( \"../data/output/SS_Extracted_content.xlsx\", index=False)\n",
    "        \n",
    "    if len( df_out.loc[ df_out[\"Id\"] == doc_id]) > 0:\n",
    "        # already processed\n",
    "        continue\n",
    "\n",
    "    resp = requests.get(url)\n",
    "\n",
    "    if resp.status_code != 200:\n",
    "        print(\"Issue in status code : \" + str(doc_id)+ \" : \"+ url + \" : \" + str(resp.status_code))\n",
    "        continue\n",
    "\n",
    "    html_doc = resp.text\n",
    "    soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "    content = \"\" # soup.title.string + \"\\n\"\n",
    "\n",
    "    for p in soup.select( \"p\"):\n",
    "        text = p.get_text()\n",
    "\n",
    "        if len( text.split()) > 1:\n",
    "            if text not in content:\n",
    "                is_in_exclude_list = False\n",
    "\n",
    "                for exclude_class in exclude_class_list:\n",
    "                    if p.has_attr(\"class\") and \\\n",
    "                        exclude_class in p.get_attribute_list( \"class\"):\n",
    "\n",
    "                        is_in_exclude_list = True\n",
    "                        break\n",
    "\n",
    "                for starts_string in exclude_starts_with: \n",
    "                    if text.startswith(starts_string):\n",
    "                        is_in_exclude_list = True\n",
    "                        break\n",
    "\n",
    "                if not is_in_exclude_list:\n",
    "                    content = content + text + \"\\n\"\n",
    "\n",
    "    title_string = soup.title.string\n",
    "\n",
    "    df_out = df_out.append( [{\"Id\":doc_id, \"url\":url, \"title\":title_string, \n",
    "                              \"html\":html_doc, \"content\":content}])\n",
    "    out_index += 1\n",
    "\n",
    "print()\n",
    "    \n",
    "df_out.to_excel( \"../data/output/SS_Extracted_content.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
