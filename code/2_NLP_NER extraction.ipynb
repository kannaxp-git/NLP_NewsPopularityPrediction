{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer, sent_tokenize, word_tokenize\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the contents\n",
    "df = pd.read_excel('../data/output/SS_Extracted_content.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sent_list\"] = None\n",
    "df[\"refined_content\"] = None\n",
    "df[\"NER_list\"] = None\n",
    "df[\"NER_most_common\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000, 2100, 2200, 2300, 2400, 2500, 2600, 2700, 2800, 2900, 3000, 3100, 3200, 3300, 3400, 3500, 3600, 3700, 3800, 3900, 4000, 4100, 4200, 4300, 4400, 4500, 4600, 4700, 4800, 4900, 5000, 5100, 5200, 5300, 5400, 5500, 5600, 5700, 5800, 5900, 6000, 6100, 6200, 6300, 6400, 6500, 6600, 6700, 6800, 6900, 7000, 7100, 7200, 7300, 7400, 7500, 7600, 7700, .\n",
      " sentences extraction complete\n"
     ]
    }
   ],
   "source": [
    "ignored_sent_count = 0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    sent_list = []\n",
    "    \n",
    "    d = str( row.content)\n",
    "    d = d.replace(\".\\n\", \". \")\n",
    "    d = d.replace(\".\\r\", \". \")\n",
    "    d = d.replace(\"\\n\", \". \")\n",
    "    d = d.replace(\"\\r\", \". \")\n",
    "    sent = sent_tokenize(d)\n",
    "    \n",
    "    sent = [ s for s in sent if s != \".\" ] # remove sentenances with only a dot\n",
    "    \n",
    "    # Ignore Non-english sentenances\n",
    "    # Sentenances with more than 50% of unicode chars are ignored\n",
    "    for each_sent in sent:\n",
    "        \n",
    "        if each_sent.startswith( \"{\\\"player\\\":{\\\"description\\\":\"):\n",
    "            continue\n",
    "        \n",
    "        non_english_count = 0\n",
    "        for c in each_sent:\n",
    "            if ord(c) > 255:\n",
    "                non_english_count += 1\n",
    "\n",
    "        if len(each_sent) > 2 and \\\n",
    "            non_english_count > len(each_sent)/2:\n",
    "\n",
    "            # ignore this sentenance\n",
    "            ignored_sent_count += 1\n",
    "        else:\n",
    "            sent_list.append( each_sent)\n",
    "            \n",
    "    \n",
    "    refined_content = \"\"\n",
    "    for sent in sent_list:\n",
    "        if len( refined_content) > 0:\n",
    "            refined_content = refined_content + \" \"\n",
    "        \n",
    "        refined_content = refined_content + sent\n",
    "    \n",
    "    df.at[index, 'sent_list'] = sent_list\n",
    "    df.at[index, 'refined_content'] = refined_content\n",
    "    \n",
    "    if index % 100 == 0:\n",
    "        print( str(index) + \", \", end='')\n",
    "    \n",
    "print( \".\\n sentences extraction complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000, 2100, 2200, 2300, 2400, 2500, 2600, 2700, 2800, 2900, 3000, 3100, 3200, 3300, 3400, 3500, 3600, 3700, 3800, 3900, 4000, 4100, 4200, 4300, 4400, 4500, 4600, 4700, 4800, 4900, 5000, 5100, 5200, 5300, 5400, 5500, 5600, 5700, 5800, 5900, 6000, 6100, 6200, 6300, 6400, 6500, 6600, 6700, 6800, 6900, 7000, 7100, 7200, 7300, 7400, 7500, 7600, 7700, .\n",
      " NER count extraction complete\n"
     ]
    }
   ],
   "source": [
    "NER_labels = set()\n",
    "for index, row in df.iterrows():\n",
    "    sample_doc = df.at[index, 'refined_content']\n",
    "    sample_doc = nlp( sample_doc)\n",
    "    \n",
    "    NER_labels.update( [x.label_ for x in sample_doc.ents])\n",
    "    \n",
    "    counter = Counter( [x.label_ for x in sample_doc.ents])\n",
    "    \n",
    "    for label in counter:\n",
    "        df.at[index, \"NER_\" + label] = counter[label]\n",
    "        \n",
    "    # extract indiviudal NER entities\n",
    "    counter = Counter([ent.text for ent in sample_doc.ents])\n",
    "    NER_list = [text for text in counter]\n",
    "    NER_most_common = [text[0] for text in counter.most_common(10)]\n",
    "    \n",
    "    df.at[index, \"NER_list\"] = \",\".join(NER_list)\n",
    "    df.at[index, \"NER_most_common\"] = \",\".join(NER_most_common)\n",
    "        \n",
    "    if index % 100 == 0:\n",
    "        print( str(index) + \", \", end='')\n",
    "        \n",
    "    \n",
    "# set NaNs in df to 0\n",
    "for label in NER_labels:\n",
    "    df[\"NER_\" + label].fillna(0, inplace=True)\n",
    "        \n",
    "print( \".\\n NER count extraction complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                 7795\n",
       "url                7795\n",
       "title              7795\n",
       "html               7795\n",
       "txt                7795\n",
       "sent_list          7795\n",
       "refined_content    7795\n",
       "NER_list           7795\n",
       "NER_most_common    7795\n",
       "NER_GPE            7795\n",
       "NER_DATE           7795\n",
       "NER_CARDINAL       7795\n",
       "NER_NORP           7795\n",
       "NER_PERSON         7795\n",
       "NER_TIME           7795\n",
       "NER_ORG            7795\n",
       "NER_WORK_OF_ART    7795\n",
       "NER_QUANTITY       7795\n",
       "NER_EVENT          7795\n",
       "NER_ORDINAL        7795\n",
       "NER_MONEY          7795\n",
       "NER_FAC            7795\n",
       "NER_PRODUCT        7795\n",
       "NER_LAW            7795\n",
       "NER_PERCENT        7795\n",
       "NER_LOC            7795\n",
       "NER_LANGUAGE       7795\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df.drop( 'sent_list', axis=1)\n",
    "\n",
    "# Write all values in one fine\n",
    "df_new.to_excel('../data/output/SS_Extracted_content_NER_all.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                 7795\n",
       "url                7795\n",
       "NER_list           7795\n",
       "NER_most_common    7795\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_NER_text = df[ ['Id', 'url', 'NER_list', 'NER_most_common']]\n",
    "df_NER_text.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NER_text.to_excel('../data/output/SS_Extracted_content_NER_text.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                 7795\n",
       "NER_GPE            7795\n",
       "NER_DATE           7795\n",
       "NER_CARDINAL       7795\n",
       "NER_NORP           7795\n",
       "NER_PERSON         7795\n",
       "NER_TIME           7795\n",
       "NER_ORG            7795\n",
       "NER_WORK_OF_ART    7795\n",
       "NER_QUANTITY       7795\n",
       "NER_EVENT          7795\n",
       "NER_ORDINAL        7795\n",
       "NER_MONEY          7795\n",
       "NER_FAC            7795\n",
       "NER_PRODUCT        7795\n",
       "NER_LAW            7795\n",
       "NER_PERCENT        7795\n",
       "NER_LOC            7795\n",
       "NER_LANGUAGE       7795\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_numeric = df.drop( ['url', 'html', 'title', 'content', 'refined_content', 'sent_list','NER_list', 'NER_most_common'], axis=1)\n",
    "df_numeric.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric.to_excel('../data/output/2_NER_Type_Count.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
